{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d4efb17",
   "metadata": {},
   "source": [
    "# Data Engineer Phase MVP:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33f38eb",
   "metadata": {},
   "source": [
    "- This notebook serves as the crucial data pipeline for the Defensive Performance Analysis project. Its purpose is to take the raw, uncleaned event data from the provided Excel file, perform all necessary data cleaning and validation checks, and transform the data into a structured format. By creating and mapping pitch zones, this notebook produces a clean, enriched dataset that is then loaded into a PostgreSQL database, ready for the next phases of analysis and visualization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "355f96db",
   "metadata": {},
   "source": [
    "1. Importing Libraries\n",
    "- This section is dedicated to importing all the Python libraries required for the data engineering phase. It includes libraries for data manipulation, numerical operations, and database connectivity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "5a0694c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import psycopg2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1a6958",
   "metadata": {},
   "source": [
    "2. Starting extracting all the data from the provided event data excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "1e7cc0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_excel_data = pd.read_csv(\"../datasets/Universitatea_Cluj_2024_2025_events.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6a76a8",
   "metadata": {},
   "source": [
    "3. Extract only the useful columns for my mvp and future analysis ideas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f8a5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_raw_excel_data = raw_excel_data[[\"id\",\"matchId\",\"matchPeriod\",\"minute\",\"second\",\"type.primary\",\"type.secondary\",\"location.x\",\"location.y\",\"team.id\",\"team.name\",\"opponentTeam.id\",\"opponentTeam.name\",\"player.id\",\"player.name\",\"pass.endLocation.x\",\"pass.endLocation.y\",\"shot.xg\",\"shot.isGoal\",\"shot.onTarget\",\"carry.endLocation.x\",\"carry.endLocation.y\",\"possession.id\",\"possession.duration\",\"possession.startLocation.x\",\"possession.startLocation.y\",\"possession.endLocation.x\",\"possession.endLocation.y\",\"competitionId\",\"seasonId\",\"Home_Away\"\n",
    "]]\n",
    "filtered_raw_excel_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f245468",
   "metadata": {},
   "source": [
    "4. Filtering the data so that we can have only the passes and carries vs UCluj"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cefb387",
   "metadata": {},
   "source": [
    "- This step focuses on filtering the raw data to isolate only the opponent's attacking movements against U Cluj. This ensures that our analysis is laser-focused on the defensive problems we're trying to solve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ac09b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_filtered_raw_excel_data = filtered_raw_excel_data[\n",
    "    ((filtered_raw_excel_data[\"type.primary\"]==\"pass\")\n",
    "    |filtered_raw_excel_data[\"type.secondary\"].apply(lambda x: 'carry' in x))&\n",
    "    (filtered_raw_excel_data[\"team.id\"]!=60374)]\n",
    "\n",
    "new_filtered_raw_excel_data[\"player.name\"] = new_filtered_raw_excel_data[\"player.name\"].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ab4bbc",
   "metadata": {},
   "source": [
    "5. Checking if the columns have unexpected null values\n",
    "- For the pass and carries end location, they are null where there is no pass or carry event corresponding for that line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7512a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_counts_per_column = new_filtered_raw_excel_data.isnull().sum()\n",
    "print(nan_counts_per_column)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df407c5",
   "metadata": {},
   "source": [
    "6. Checking if the values for coordinates are accordingly ( between 0-100 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5210e8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "is_x_valid = (new_filtered_raw_excel_data[\"location.x\"] >= 0) & (new_filtered_raw_excel_data[\"location.x\"]  <= 100)\n",
    "is_y_valid = (new_filtered_raw_excel_data[\"location.y\"] >= 0) & (new_filtered_raw_excel_data[\"location.y\"] <= 100)\n",
    "\n",
    "is_pass_endloc_x_valid = (new_filtered_raw_excel_data[\"pass.endLocation.x\"].notnull() >= 0) & (new_filtered_raw_excel_data[\"pass.endLocation.x\"].notnull() <= 100)\n",
    "is_pass_endloc_y_valid = (new_filtered_raw_excel_data[\"pass.endLocation.y\"].notnull() >= 0) & (new_filtered_raw_excel_data[\"pass.endLocation.y\"].notnull() <= 100)\n",
    "\n",
    "\n",
    "\n",
    "all_x_are_valid = is_x_valid.all()\n",
    "all_y_are_valid = is_y_valid.all()\n",
    "all_passx_are_valid = is_pass_endloc_x_valid.all()\n",
    "all_passy_are_valid = is_pass_endloc_y_valid.all()\n",
    "\n",
    "\n",
    "print(f\"All 'location.x' values are valid: {all_x_are_valid}\")\n",
    "print(f\"All 'location.y' values are valid: {all_y_are_valid}\")\n",
    "print(f\"All 'location.x' values are valid: {all_passx_are_valid}\")\n",
    "print(f\"All 'location.y' values are valid: {all_passy_are_valid}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beeb3c92",
   "metadata": {},
   "source": [
    "7. Developing the function for assigning the coordinates in a specific zone from a 16x12 grid size pitch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "8a86e36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculating_pitch_zone_assignation(x,y):\n",
    "    row = x//6.25\n",
    "    column = y//8.33\n",
    "    result = \"zone_\"+str(int(row))+\"_\"+str(int(column))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e35b22e",
   "metadata": {},
   "source": [
    "8. Applying the zone function for both passes and carries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b508cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new, explicit copy of the filtered data\n",
    "df_for_zone_mapping = new_filtered_raw_excel_data.copy()\n",
    "\n",
    "# Now, apply your calculations to this copy\n",
    "df_for_zone_mapping[\"start_zone\"] = df_for_zone_mapping.apply(\n",
    "    lambda row: calculating_pitch_zone_assignation(row[\"location.x\"], row[\"location.y\"]),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "df_for_zone_mapping[\"end_zone\"] = df_for_zone_mapping.apply(\n",
    "    lambda row:\n",
    "        calculating_pitch_zone_assignation(row[\"pass.endLocation.x\"], row[\"pass.endLocation.y\"])\n",
    "        if not pd.isnull(row[\"pass.endLocation.x\"])\n",
    "        else calculating_pitch_zone_assignation(row[\"carry.endLocation.x\"], row[\"carry.endLocation.y\"]),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "df_for_zone_mapping.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454d9512",
   "metadata": {},
   "source": [
    "9. Connect to the local PostgreSQL database and execute the SQL queries to create a new schema, create a new table for the cleaned data, and insert the cleaned data into it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91cacd2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_sql(file_path: str) -> str:\n",
    "    with open(file_path, \"r\") as file:\n",
    "        query = file.read()\n",
    "        return query\n",
    "def execute_structural_query(sql: str) -> None:\n",
    "    conn = psycopg2.connect(\n",
    "        dbname=\"postgres\",\n",
    "        user=\"postgres\",\n",
    "        password=\"placeholder\",\n",
    "        host=\"localhost\",\n",
    "        port=5432\n",
    "    )\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(sql)\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "def execute_insert_query(sql: str,data:list) -> None:\n",
    "    conn = psycopg2.connect(\n",
    "        dbname=\"postgres\",\n",
    "        user=\"postgres\",\n",
    "        password=\"placeholder\",\n",
    "        host=\"localhost\",\n",
    "        port=5432\n",
    "    )\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(read_sql(sql),data)\n",
    "    conn.commit()\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d05afff",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ ==\"__main__\":  \n",
    "    query_paths_structure = [\n",
    "        \"./SQL_Queries/creating_frf_schema.sql\",\n",
    "        \"./SQL_Queries/create_raw_data_table.sql\"\n",
    "        ]\n",
    "    for query_path in query_paths_structure:\n",
    "        sql_query = read_sql(query_path)\n",
    "        execute_structural_query(sql_query)\n",
    "        #print(\"done\")\n",
    "    \n",
    "    for _, row in df_for_zone_mapping.iterrows():\n",
    "        row_list = row.tolist()\n",
    "        execute_insert_query(\"./SQL_Queries/insert_raw_data.sql\",row_list)\n",
    "        #print(\"done\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
